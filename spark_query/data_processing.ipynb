{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "path_directory = \"/home/oem/PycharmProjects/RealEstate_Data_Pipeline/processed_data/.ipynb_checkpoints/combined_data-checkpoint.csv\"\n",
    "path_direct2 = \"/home/oem/PycharmProjects/RealEstate_Data_Pipeline/spark_query/dataframe1.csv\""
   ],
   "id": "4b5cb88b3d638666",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Loadin function\n",
    "def load_data(path_directory, path_direct2):\n",
    "    df1 = pd.read_csv(path_directory, low_memory=False)\n",
    "    df2 = pd.read_csv(path_direct2, low_memory=False)\n",
    "    \n",
    "    for cols in df1.columns:\n",
    "        if df1[cols].apply(type).nunique() > 1:\n",
    "            print(f\"These col: {cols} has mixed data type in df1\")\n",
    "    \n",
    "    for cols in df2.columns:\n",
    "        if df2[cols].apply(type).nunique() > 1:\n",
    "            print(f\"These col: {cols} has mixed data type in df2\")\n",
    "    return df1, df2"
   ],
   "id": "4ca9883c7bdd313b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df1, df2 = load_data(path_directory, path_direct2)",
   "id": "c9df1a6d4e8c442d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df1.dtypes",
   "id": "55334cb3b8751af3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Correcting the dtype of columns\n",
    "def correcting_dtypes(df1, df2):\n",
    "    cols_affected = [\n",
    "        \"State\",\n",
    "        \"City\",\n",
    "        \"Metro\",\n",
    "        \"CountyName\",\n",
    "        \"StateName\"\n",
    "    ]\n",
    "\n",
    "    for col in cols_affected:\n",
    "        if isinstance(df1[col], object):\n",
    "            df1[col] = df1[col].astype(str)\n",
    "        else:\n",
    "            if isinstance(df2[col], object):\n",
    "                df2[col] = df2[col].astype(str)\n",
    "\n",
    "    return df1, df2"
   ],
   "id": "dced2d6425b0b3ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df1 = correcting_dtypes(df1)\n",
    "df1.head(10)"
   ],
   "id": "e9ede0200faa960f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Droping abnormal columns\n",
    "def clean_data(df):\n",
    "    df = df.drop(columns=['City', 'StateCodeFIPS', \"MunicipalCodeFIPS\"], axis=1)\n",
    "    print(df.duplicated(keep='first').sum())\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    return df"
   ],
   "id": "789beecc4e6b8273",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df1 = clean_data(df1)",
   "id": "c81565a05d14f779",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_quarter_prices(df, quarter, year_start=2000, year_end=2024):\n",
    "    \n",
    "    quarter_months = {\n",
    "        \"first\": [\"01-31\", \"02-28\", \"03-31\"],\n",
    "        \"second\": [\"04-30\", \"05-31\", \"06-30\"],\n",
    "        \"third\": [\"07-31\", \"08-31\", \"09-30\"],\n",
    "        \"fourth\": [\"10-31\", \"11-30\", \"12-31\"]\n",
    "    }\n",
    "\n",
    "    if quarter not in quarter_months:\n",
    "        raise ValueError(f\"Invalid quarter name: {quarter}. Must be one of: {list(quarter_months.keys())}\")\n",
    "\n",
    "    months = quarter_months[quarter]\n",
    "\n",
    "    for year in range(year_start, year_end + 1):\n",
    "        # Adjust February for leap years if it's the first quarter\n",
    "        if quarter == \"first\" and pd.Timestamp(f\"{year}-02-01\").is_leap_year:\n",
    "            months[1] = \"02-29\"  # Replace 02-28 with 02-29 for leap years\n",
    "        else:\n",
    "            months[1] = \"02-28\"  # Reset to 02-28 for non-leap years\n",
    "\n",
    "        # Generate the column names for the quarter\n",
    "        date_columns = [f\"{year}-{month}\" for month in months]\n",
    "\n",
    "        # Check for missing columns\n",
    "        missing_cols = [col for col in date_columns if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"Warning: Missing columns for {year} {quarter}: {missing_cols}\")\n",
    "            continue\n",
    "            \n",
    "        df1 = df\n",
    "        df1 = df1.copy()\n",
    "        \n",
    "        # Calculate the average and add the new column\n",
    "        column_name = f\"{year}_{quarter}_qtr_prices\"\n",
    "        df1[column_name] = df1[date_columns].mean(axis=1).round(2)\n",
    "\n",
    "    return df1\n",
    "\n",
    "calculate_quarter_prices(texas_df, quarter=\"first\")"
   ],
   "id": "e4a8370b0c61b99d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_state_dfs(df):\n",
    "    # List of states\n",
    "    states = [\n",
    "        \"TX\", \"CA\", \"NY\", \"FL\", \"IL\",\n",
    "        \"OH\", \"GA\", \"MA\", \"VA\", \"WA\",\n",
    "        \"PA\", \"NC\", \"CO\", \"MN\", \"IN\",\n",
    "        \"MI\", \"IA\", \"MD\", \"KS\", \"UT\", \"OR\"\n",
    "    ]\n",
    "    \n",
    "    # Create a dictionary of DataFrames for each state\n",
    "    state_dfs = {state: df[df[\"State\"] == state] for state in states}\n",
    "    \n",
    "    return state_dfs\n"
   ],
   "id": "1db0db69196359a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "state_dfs = create_state_dfs(df1)\n",
    "\n",
    "# Access specific state DataFrames\n",
    "tx_df = state_dfs[\"TX\"]\n",
    "fl_df = state_dfs[\"FL\"]\n",
    "oh_df = state_dfs[\"OH\"]"
   ],
   "id": "751c3627555b361a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tx_df.head()",
   "id": "696a99a25767b205",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2bdfa2878d638f29",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
